{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import batch_norm\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def load_data(csv_path):\n",
    "    return pd.read_csv(csv_path)\n",
    "\n",
    "#def rmsle(y, y0):\n",
    "#    return tf.sqrt(tf.reduce_mean(tf.pow(tf.log1p(y)-tf.log1p(y0), 2)))\n",
    "def rmsle(actual, predicted):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        actual (1d-array [nx1]) - array of actual values (float)\n",
    "        predicted (1d-array [nx1]) - array of predicted values (float)\n",
    "    Returns:\n",
    "        root mean square log error (float)\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(actual)-np.log1p(predicted), 2)))\n",
    "\n",
    "def display_rmsle(y_pred_f, y_pred_b, y_f, y_b):\n",
    "    rmsle_f = rmsle(y_f, y_pred_f)\n",
    "    rmsle_b = rmsle(y_b, y_pred_b)\n",
    "    print (\"RMSLE: \", (rmsle_f + rmsle_b) / 2)\n",
    "\n",
    "objective  = make_scorer(rmsle, greater_is_better=False)\n",
    "\n",
    "def drop_features(df_t):\n",
    "    df = df_t.copy()\n",
    "    df = df.drop('id', 1)\n",
    "    df = df.drop(\"formation_energy_ev_natom\", 1)\n",
    "    df = df.drop(\"bandgap_energy_ev\", 1)\n",
    "    return df\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Expected LB\")\n",
    "    print(\"Scores: \", scores)\n",
    "    print(\"Mean: \", scores.mean())\n",
    "    print(\"Standard deviation: \", scores.std())\n",
    "    \n",
    "def encode_scale(df):\n",
    "    X = df\n",
    "    encoded_matrix = OneHotEncoder(sparse=False).fit_transform(X['spacegroup'].values.reshape(-1,1))\n",
    "    X = X.drop(\"spacegroup\", 1)\n",
    "    encoded_df = pd.DataFrame(data=encoded_matrix, dtype=np.float64)\n",
    "    X_encoded = pd.concat([X, encoded_df], axis=1).reindex()\n",
    "    print(X_encoded)\n",
    "    X_scaled = StandardScaler().fit_transform(X_encoded)\n",
    "    \n",
    "    myEncoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "    myEncoder.fit(df[columnsToEncode])\n",
    "    pd.concat([X, pd.DataFrame(myEncoder.transform(df[columnsToEncode]))], axis=1).reindex()\n",
    "    return X_scaled\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "def encode(df):\n",
    "    numerical_attrbs = list(df)\n",
    "    del numerical_attrbs[0]\n",
    "\n",
    "    label_attrbs = ['spacegroup']\n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.pipeline import FeatureUnion\n",
    "    pl1 = Pipeline([\n",
    "        ('selector', DataFrameSelector(numerical_attrbs)),\n",
    "        ('scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    pl2 = Pipeline([\n",
    "        ('selector', DataFrameSelector(label_attrbs)),\n",
    "        ('one_hot', OneHotEncoder())\n",
    "    ])\n",
    "\n",
    "    full_pl = FeatureUnion(transformer_list=[\n",
    "        ('numerical', pl1),\n",
    "        ('label',     pl2),\n",
    "    ])\n",
    "    data_prepared = full_pl.fit_transform(df)\n",
    "    return pd.DataFrame(data_prepared.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare data sets\n",
    "df_t = load_data('/home/agi/Desktop/NOMAD/data/train_prepared.csv')\n",
    "df_s = load_data('/home/agi/Desktop/NOMAD/data/test_prepared.csv')\n",
    "\n",
    "train_set, test_set = train_test_split(df_t, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = encode(drop_features(train_set))\n",
    "X_test  = encode(drop_features(test_set))\n",
    "X_submt = encode(drop_features(df_s))\n",
    "                       \n",
    "y_form = train_set[\"formation_energy_ev_natom\"]\n",
    "y_band = train_set[\"bandgap_energy_ev\"]\n",
    "                       \n",
    "y_form_test = test_set[\"formation_energy_ev_natom\"]\n",
    "y_band_test = test_set[\"bandgap_energy_ev\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "n_inputs = 30\n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 200\n",
    "n_hidden3 = 100\n",
    "n_hidden4 = 100\n",
    "n_hidden5 = 100\n",
    "n_hidden6 = 50\n",
    "n_hidden7 = 50\n",
    "n_outputs = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "reset_graph()\n",
    "\n",
    "batch_norm_momentum = 0.9\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None), name=\"y\")\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "\n",
    "with tf.name_scope(\"dnn\"):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "\n",
    "    my_batch_norm_layer = partial(\n",
    "            tf.layers.batch_normalization,\n",
    "            training=training,\n",
    "            momentum=batch_norm_momentum)\n",
    "\n",
    "    my_dense_layer = partial(\n",
    "            tf.layers.dense,\n",
    "            kernel_initializer=he_init)\n",
    "\n",
    "    hidden1 = my_dense_layer(X, n_hidden1, name=\"hidden1\")\n",
    "    bn1 = tf.nn.elu(my_batch_norm_layer(hidden1))\n",
    "    hidden2 = my_dense_layer(bn1, n_hidden2, name=\"hidden2\")\n",
    "    bn2 = tf.nn.elu(my_batch_norm_layer(hidden2))\n",
    "    hidden3 = my_dense_layer(bn2, n_hidden3, name=\"hidden3\")\n",
    "    bn3 = tf.nn.elu(my_batch_norm_layer(hidden3))\n",
    "    logits_before_bn = my_dense_layer(bn3, n_outputs, name=\"outputs\")\n",
    "    logits = my_batch_norm_layer(logits_before_bn)\n",
    "    \n",
    "with tf.name_scope(\"loss\"):\n",
    "    mse = tf.losses.mean_squared_error(labels=y, predictions=logits)\n",
    "    loss = tf.sqrt(mse, name=\"loss\")\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "    \n",
    "with tf.name_scope(\"eval\"):\n",
    "    mse_eval = tf.losses.mean_squared_error(y, logits)\n",
    "    \n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train MSE: 0.000108592 Test MSE: 0.0211013\n",
      "1 Train MSE: 0.000221666 Test MSE: 0.0231636\n",
      "2 Train MSE: 0.000344633 Test MSE: 0.0180247\n",
      "3 Train MSE: 3.3325e-05 Test MSE: 0.0199028\n",
      "4 Train MSE: 6.75643e-05 Test MSE: 0.0237235\n",
      "5 Train MSE: 3.34294e-05 Test MSE: 0.0261064\n",
      "6 Train MSE: 0.000496724 Test MSE: 0.0236852\n",
      "7 Train MSE: 0.000323696 Test MSE: 0.021026\n",
      "8 Train MSE: 0.00303616 Test MSE: 0.0234125\n",
      "9 Train MSE: 4.0864e-05 Test MSE: 0.0265094\n",
      "10 Train MSE: 4.26366e-05 Test MSE: 0.0188494\n",
      "11 Train MSE: 3.71971e-05 Test MSE: 0.0217199\n",
      "12 Train MSE: 1.66138e-05 Test MSE: 0.0222932\n",
      "13 Train MSE: 7.05345e-08 Test MSE: 0.0234318\n",
      "14 Train MSE: 9.47027e-05 Test MSE: 0.0257284\n",
      "15 Train MSE: 0.000275343 Test MSE: 0.0227877\n",
      "16 Train MSE: 5.97976e-06 Test MSE: 0.0206599\n",
      "17 Train MSE: 4.91789e-05 Test MSE: 0.0204063\n",
      "18 Train MSE: 1.7469e-06 Test MSE: 0.0198834\n",
      "19 Train MSE: 9.40403e-05 Test MSE: 0.0214879\n",
      "20 Train MSE: 3.93691e-05 Test MSE: 0.0205828\n",
      "21 Train MSE: 8.42047e-05 Test MSE: 0.0243414\n",
      "22 Train MSE: 0.000213342 Test MSE: 0.019697\n",
      "23 Train MSE: 7.15164e-05 Test MSE: 0.0229257\n",
      "24 Train MSE: 0.000184816 Test MSE: 0.0215444\n",
      "25 Train MSE: 0.000132724 Test MSE: 0.0206305\n",
      "26 Train MSE: 5.65243e-05 Test MSE: 0.0227232\n",
      "27 Train MSE: 0.00014056 Test MSE: 0.0228883\n",
      "28 Train MSE: 0.000260039 Test MSE: 0.0212429\n",
      "29 Train MSE: 9.2544e-05 Test MSE: 0.0201216\n",
      "30 Train MSE: 3.24575e-05 Test MSE: 0.0229418\n",
      "31 Train MSE: 0.000126389 Test MSE: 0.0199888\n",
      "32 Train MSE: 0.000228431 Test MSE: 0.0195451\n",
      "33 Train MSE: 0.000490095 Test MSE: 0.0205166\n",
      "34 Train MSE: 0.000134532 Test MSE: 0.0216587\n",
      "35 Train MSE: 5.85766e-07 Test MSE: 0.0224263\n",
      "36 Train MSE: 0.000103442 Test MSE: 0.0197162\n",
      "37 Train MSE: 0.000254718 Test MSE: 0.0220472\n",
      "38 Train MSE: 9.29275e-05 Test MSE: 0.0219166\n",
      "39 Train MSE: 0.000190907 Test MSE: 0.0231043\n",
      "40 Train MSE: 1.91418e-07 Test MSE: 0.0234554\n",
      "41 Train MSE: 0.000205485 Test MSE: 0.0215145\n",
      "42 Train MSE: 0.000317921 Test MSE: 0.0237363\n",
      "43 Train MSE: 0.000280607 Test MSE: 0.019815\n",
      "44 Train MSE: 0.000158628 Test MSE: 0.0192766\n",
      "45 Train MSE: 1.05955e-06 Test MSE: 0.0209813\n",
      "46 Train MSE: 0.000132655 Test MSE: 0.0214208\n",
      "47 Train MSE: 0.000237972 Test MSE: 0.0210867\n",
      "48 Train MSE: 1.16204e-06 Test MSE: 0.0232454\n",
      "49 Train MSE: 1.15225e-07 Test MSE: 0.0212821\n",
      "50 Train MSE: 0.00061281 Test MSE: 0.023979\n",
      "51 Train MSE: 0.000117377 Test MSE: 0.0254712\n",
      "52 Train MSE: 8.22578e-05 Test MSE: 0.0233096\n",
      "53 Train MSE: 7.92894e-05 Test MSE: 0.02306\n",
      "54 Train MSE: 6.21959e-07 Test MSE: 0.0217368\n",
      "55 Train MSE: 0.000239966 Test MSE: 0.019469\n",
      "56 Train MSE: 0.000318072 Test MSE: 0.0199305\n",
      "57 Train MSE: 5.13229e-05 Test MSE: 0.0210023\n",
      "58 Train MSE: 0.000199179 Test MSE: 0.0198472\n",
      "59 Train MSE: 0.000451683 Test MSE: 0.0206471\n",
      "60 Train MSE: 1.61892e-05 Test MSE: 0.0193801\n",
      "61 Train MSE: 0.000235108 Test MSE: 0.0197964\n",
      "62 Train MSE: 0.000188898 Test MSE: 0.0225504\n",
      "63 Train MSE: 0.000112704 Test MSE: 0.0232072\n",
      "64 Train MSE: 7.42157e-05 Test MSE: 0.0222257\n",
      "65 Train MSE: 7.79225e-05 Test MSE: 0.0197735\n",
      "66 Train MSE: 8.44013e-06 Test MSE: 0.0211132\n",
      "67 Train MSE: 2.14562e-05 Test MSE: 0.020353\n",
      "68 Train MSE: 0.000146062 Test MSE: 0.0188886\n",
      "69 Train MSE: 1.44373e-05 Test MSE: 0.021657\n",
      "70 Train MSE: 9.32787e-06 Test MSE: 0.0224909\n",
      "71 Train MSE: 5.6395e-05 Test MSE: 0.0219565\n",
      "72 Train MSE: 0.000263124 Test MSE: 0.0217673\n",
      "73 Train MSE: 0.000167669 Test MSE: 0.0201798\n",
      "74 Train MSE: 7.95391e-06 Test MSE: 0.0234472\n",
      "75 Train MSE: 1.92197e-05 Test MSE: 0.0218264\n",
      "76 Train MSE: 4.75095e-05 Test MSE: 0.0283302\n",
      "77 Train MSE: 0.000113479 Test MSE: 0.0201324\n",
      "78 Train MSE: 0.000234642 Test MSE: 0.01969\n",
      "79 Train MSE: 0.000109152 Test MSE: 0.0243363\n",
      "80 Train MSE: 6.838e-05 Test MSE: 0.0201253\n",
      "81 Train MSE: 0.000119574 Test MSE: 0.02122\n",
      "82 Train MSE: 0.000208034 Test MSE: 0.0206385\n",
      "83 Train MSE: 4.46104e-05 Test MSE: 0.0203962\n",
      "84 Train MSE: 3.33101e-05 Test MSE: 0.024142\n",
      "85 Train MSE: 2.46972e-05 Test MSE: 0.0210839\n",
      "86 Train MSE: 2.47852e-07 Test MSE: 0.0197958\n",
      "87 Train MSE: 5.7529e-06 Test MSE: 0.0207272\n",
      "88 Train MSE: 1.43776e-05 Test MSE: 0.0213407\n",
      "89 Train MSE: 0.000221221 Test MSE: 0.0199697\n",
      "90 Train MSE: 2.15989e-05 Test MSE: 0.021475\n",
      "91 Train MSE: 9.47204e-05 Test MSE: 0.0191513\n",
      "92 Train MSE: 9.11867e-05 Test MSE: 0.0230904\n",
      "93 Train MSE: 0.000151361 Test MSE: 0.0185935\n",
      "94 Train MSE: 0.000214673 Test MSE: 0.0245637\n",
      "95 Train MSE: 8.57705e-05 Test MSE: 0.022946\n",
      "96 Train MSE: 0.00019325 Test MSE: 0.0219307\n",
      "97 Train MSE: 7.21261e-05 Test MSE: 0.0216192\n",
      "98 Train MSE: 0.000155297 Test MSE: 0.0216934\n",
      "99 Train MSE: 0.000126285 Test MSE: 0.023601\n",
      "0 Train MSE: 0.0905682 Test MSE: 1.65289\n",
      "1 Train MSE: 0.00308719 Test MSE: 1.80156\n",
      "2 Train MSE: 0.00105642 Test MSE: 1.7515\n",
      "3 Train MSE: 0.000930857 Test MSE: 1.84385\n",
      "4 Train MSE: 0.00390738 Test MSE: 1.70156\n",
      "5 Train MSE: 0.00784353 Test MSE: 1.99158\n",
      "6 Train MSE: 0.00153554 Test MSE: 1.83931\n",
      "7 Train MSE: 0.00208416 Test MSE: 1.84523\n",
      "8 Train MSE: 0.000384437 Test MSE: 1.93829\n",
      "9 Train MSE: 8.04271e-05 Test MSE: 1.825\n",
      "10 Train MSE: 0.000395074 Test MSE: 1.88066\n",
      "11 Train MSE: 0.000509067 Test MSE: 2.1075\n",
      "12 Train MSE: 0.00768492 Test MSE: 1.9176\n",
      "13 Train MSE: 0.0163898 Test MSE: 1.99263\n",
      "14 Train MSE: 0.00489982 Test MSE: 1.80713\n",
      "15 Train MSE: 0.000131831 Test MSE: 1.9107\n",
      "16 Train MSE: 0.0111122 Test MSE: 1.87068\n",
      "17 Train MSE: 0.0113167 Test MSE: 1.75975\n",
      "18 Train MSE: 0.0165138 Test MSE: 2.04569\n",
      "19 Train MSE: 0.000171227 Test MSE: 1.78353\n",
      "20 Train MSE: 0.00997544 Test MSE: 2.05932\n",
      "21 Train MSE: 0.00309703 Test MSE: 1.78546\n",
      "22 Train MSE: 0.00856789 Test MSE: 2.01288\n",
      "23 Train MSE: 0.000535987 Test MSE: 1.97415\n",
      "24 Train MSE: 5.40325e-05 Test MSE: 1.94217\n",
      "25 Train MSE: 0.00673132 Test MSE: 1.80531\n",
      "26 Train MSE: 7.90263e-05 Test MSE: 1.95125\n",
      "27 Train MSE: 0.00116517 Test MSE: 1.86448\n",
      "28 Train MSE: 0.00663732 Test MSE: 1.94386\n",
      "29 Train MSE: 0.014365 Test MSE: 2.1101\n",
      "30 Train MSE: 0.00272821 Test MSE: 1.79304\n",
      "31 Train MSE: 0.000183455 Test MSE: 1.77693\n",
      "32 Train MSE: 0.00420575 Test MSE: 1.93196\n",
      "33 Train MSE: 9.77524e-05 Test MSE: 1.94305\n",
      "34 Train MSE: 0.00881899 Test MSE: 2.14281\n",
      "35 Train MSE: 0.00077942 Test MSE: 1.85326\n",
      "36 Train MSE: 0.0074599 Test MSE: 1.83642\n",
      "37 Train MSE: 0.00754477 Test MSE: 1.9043\n",
      "38 Train MSE: 0.000165817 Test MSE: 2.13312\n",
      "39 Train MSE: 0.00376861 Test MSE: 1.93338\n",
      "40 Train MSE: 0.00453932 Test MSE: 1.90858\n",
      "41 Train MSE: 0.000607592 Test MSE: 1.92839\n",
      "42 Train MSE: 0.00037388 Test MSE: 1.94143\n",
      "43 Train MSE: 0.00126546 Test MSE: 1.90161\n",
      "44 Train MSE: 0.00410166 Test MSE: 2.0064\n",
      "45 Train MSE: 0.0015156 Test MSE: 1.90006\n",
      "46 Train MSE: 0.00400129 Test MSE: 1.78204\n",
      "47 Train MSE: 0.000653382 Test MSE: 1.9131\n",
      "48 Train MSE: 0.0136381 Test MSE: 2.02934\n",
      "49 Train MSE: 0.000244513 Test MSE: 1.93248\n",
      "50 Train MSE: 0.000277682 Test MSE: 1.99528\n",
      "51 Train MSE: 0.00506053 Test MSE: 1.98229\n",
      "52 Train MSE: 0.00290138 Test MSE: 2.12651\n",
      "53 Train MSE: 0.000673054 Test MSE: 1.85145\n",
      "54 Train MSE: 0.0090323 Test MSE: 2.01949\n",
      "55 Train MSE: 0.00967878 Test MSE: 1.92318\n",
      "56 Train MSE: 0.00298421 Test MSE: 1.955\n",
      "57 Train MSE: 0.00161897 Test MSE: 1.86833\n",
      "58 Train MSE: 8.68114e-06 Test MSE: 1.85955\n",
      "59 Train MSE: 0.000127509 Test MSE: 2.03171\n",
      "60 Train MSE: 0.00139659 Test MSE: 1.95284\n",
      "61 Train MSE: 0.0121732 Test MSE: 2.08232\n",
      "62 Train MSE: 0.00143574 Test MSE: 1.92925\n",
      "63 Train MSE: 0.000130782 Test MSE: 2.06361\n",
      "64 Train MSE: 0.000439395 Test MSE: 1.94889\n",
      "65 Train MSE: 1.62216e-05 Test MSE: 2.05783\n",
      "66 Train MSE: 0.00218561 Test MSE: 1.75929\n",
      "67 Train MSE: 0.00358764 Test MSE: 1.9238\n",
      "68 Train MSE: 0.00565319 Test MSE: 1.98824\n",
      "69 Train MSE: 0.0117464 Test MSE: 1.97375\n",
      "70 Train MSE: 0.00133315 Test MSE: 2.01988\n",
      "71 Train MSE: 0.00902188 Test MSE: 1.90507\n",
      "72 Train MSE: 0.00598352 Test MSE: 2.01114\n",
      "73 Train MSE: 0.000149787 Test MSE: 1.86234\n",
      "74 Train MSE: 0.00532182 Test MSE: 1.92937\n",
      "75 Train MSE: 0.00443059 Test MSE: 1.92441\n",
      "76 Train MSE: 0.00245311 Test MSE: 2.12243\n",
      "77 Train MSE: 0.0166682 Test MSE: 2.02022\n",
      "78 Train MSE: 2.04859e-05 Test MSE: 1.88311\n",
      "79 Train MSE: 0.00273195 Test MSE: 1.91589\n",
      "80 Train MSE: 0.00153338 Test MSE: 2.01756\n",
      "81 Train MSE: 8.14007e-05 Test MSE: 1.80121\n",
      "82 Train MSE: 0.00134805 Test MSE: 1.89244\n",
      "83 Train MSE: 2.67695e-05 Test MSE: 1.95079\n",
      "84 Train MSE: 3.20902e-07 Test MSE: 2.08539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 Train MSE: 0.000335538 Test MSE: 2.02594\n",
      "86 Train MSE: 0.0151014 Test MSE: 2.0882\n",
      "87 Train MSE: 0.00786817 Test MSE: 2.06606\n",
      "88 Train MSE: 0.000564802 Test MSE: 1.82002\n",
      "89 Train MSE: 0.00933171 Test MSE: 1.9973\n",
      "90 Train MSE: 0.00059053 Test MSE: 2.04094\n",
      "91 Train MSE: 0.00134946 Test MSE: 1.85654\n",
      "92 Train MSE: 0.00160989 Test MSE: 2.03373\n",
      "93 Train MSE: 0.00575626 Test MSE: 1.99238\n",
      "94 Train MSE: 0.00794661 Test MSE: 2.00614\n",
      "95 Train MSE: 0.000109225 Test MSE: 2.06673\n",
      "96 Train MSE: 0.00401424 Test MSE: 1.86212\n",
      "97 Train MSE: 0.0107306 Test MSE: 2.04763\n",
      "98 Train MSE: 0.00348855 Test MSE: 2.01398\n",
      "99 Train MSE: 0.000555312 Test MSE: 1.91973\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "batch_size = 1\n",
    "preds_form = None\n",
    "preds_band = None\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(X_train.shape[0] // batch_size):\n",
    "            X_batch, y_batch = (X_train[iteration*batch_size:(iteration+1)*batch_size], \n",
    "                y_form[iteration*batch_size:(iteration+1)*batch_size])\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = mse_eval.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = mse_eval.eval(feed_dict={X: X_test, y: y_form})\n",
    "        print(epoch, \"Train MSE:\", acc_train, \"Test MSE:\", acc_test)\n",
    "    feed_dict_f = {X: X_test}\n",
    "    preds_form = sess.run(logits, feed_dict_f)\n",
    "    submit_pred_form = sess.run(logits, {X: X_submt})\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(X_train.shape[0] // batch_size):\n",
    "            X_batch, y_batch = (X_train[iteration*batch_size:(iteration+1)*batch_size], \n",
    "                y_band[iteration*batch_size:(iteration+1)*batch_size])\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_train = mse_eval.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        acc_test = mse_eval.eval(feed_dict={X: X_test, y: y_band})\n",
    "        print(epoch, \"Train MSE:\", acc_train, \"Test MSE:\", acc_test)\n",
    "    feed_dict_b = {X: X_test}\n",
    "    preds_band = sess.run(logits, feed_dict_b)\n",
    "    submit_pred_band = sess.run(logits, {X: X_submt})\n",
    "    #save_path = saver.save(sess, \"./my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE:  0.288322903515\n"
     ]
    }
   ],
   "source": [
    "display_rmsle(preds_form, preds_band, y_form_test.as_matrix(), y_band_test.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build submission .csv\n",
    "submission = np.concatenate((submit_pred_form.reshape(600,1), submit_pred_band.reshape(600,1)), axis=1)\n",
    "submit_df = pd.DataFrame(submission, columns=['formation_energy_ev_natom', \"bandgap_energy_ev\"])\n",
    "submit_df[submit_df < 0] = 0\n",
    "submit_df.insert(0, 'id', range(1, 601))\n",
    "\n",
    "# Save to file\n",
    "submit_df.to_csv(\"/home/agi/Desktop/NOMAD/submissions/dnn_1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
